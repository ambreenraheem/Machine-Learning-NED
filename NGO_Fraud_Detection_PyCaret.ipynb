{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193fbd99",
   "metadata": {},
   "source": [
    "# NGO Fraud Detection â€” PyCaret + EDA\n",
    "\n",
    "**Notebook:** `NGO_Fraud_Detection_PyCaret.ipynb`\n",
    "\n",
    "**Purpose:** This notebook performs Exploratory Data Analysis (EDA) and builds a fraud-detection model using PyCaret. It is written in professional English for use in a GitHub portfolio.\n",
    "\n",
    "**Dataset:** `pakistan_ngo_fraud_perfect_dataset.csv` (target column: `Is_Fraud` with values TRUE/FALSE)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68af98c",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "This section installs required packages (if needed) and imports Python libraries used across the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c3f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyCaret (uncomment if running in a new environment)\n",
    "# !pip install pycaret\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6f5b5",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Load the CSV file into a pandas DataFrame and preview basic information. Make sure `pakistan_ngo_fraud_perfect_dataset.csv` is in the same directory or provide a correct path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt/data/pakistan_ngo_fraud_perfect_dataset.csv'\n",
    "\n",
    "# Load\n",
    "if not Path(DATA_PATH).exists():\n",
    "    print(f'Warning: {DATA_PATH} not found in the working directory. Please upload the file to run this notebook.')\n",
    "else:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    display(df.head())\n",
    "    print('\\nShape:', df.shape)\n",
    "    print('\\nColumns:', list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130fb596",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "The following cells examine the data distribution, fraud vs non-fraud counts, and top categories linked to fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb71016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info & null counts\n",
    "try:\n",
    "    display(df.info())\n",
    "    display(df.isnull().sum())\n",
    "except NameError:\n",
    "    print('Load the dataset first (run the cell above).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime if present\n",
    "try:\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df['year'] = df['Date'].dt.year\n",
    "        df['month'] = df['Date'].dt.month\n",
    "        print('Date converted. Sample:')\n",
    "        display(df[['Date']].head())\n",
    "except Exception as e:\n",
    "    print('Date conversion skipped or failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure target column is boolean / binary\n",
    "try:\n",
    "    if 'Is_Fraud' in df.columns:\n",
    "        print('Unique values in Is_Fraud:', df['Is_Fraud'].unique())\n",
    "        # Normalize values to boolean 1/0\n",
    "        df['Is_Fraud_bool'] = df['Is_Fraud'].map({True:1, False:0, 'TRUE':1, 'True':1, 'true':1, 'FALSE':0, 'False':0, 'false':0, '1':1, '0':0}).astype('Int64')\n",
    "        print('\\nValue counts (Is_Fraud_bool):')\n",
    "        display(df['Is_Fraud_bool'].value_counts(dropna=False))\n",
    "    else:\n",
    "        print('Is_Fraud column not found. Please check dataset.')\n",
    "except Exception as e:\n",
    "    print('Error handling Is_Fraud column:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Fraud vs Non-Fraud count\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.countplot(x='Is_Fraud_bool', data=df, palette='pastel')\n",
    "    ax.set_xticklabels(['Non-Fraud (0)', 'Fraud (1)'])\n",
    "    ax.set_title('Fraud vs Non-Fraud Count')\n",
    "    plt.show()\n",
    "except NameError:\n",
    "    print('Load the dataset first (run the cell above).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 NGOs by number of fraud cases\n",
    "try:\n",
    "    if 'NGO_Name' in df.columns:\n",
    "        top_ngos = df[df['Is_Fraud_bool']==1]['NGO_Name'].value_counts().head(10)\n",
    "        display(top_ngos)\n",
    "        plt.figure(figsize=(10,4))\n",
    "        sns.barplot(x=top_ngos.values, y=top_ngos.index, palette='magma')\n",
    "        plt.title('Top 10 NGOs by Fraud Count')\n",
    "        plt.xlabel('Fraud Count')\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print('NGO plot skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76840337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Vendors by fraud cases\n",
    "try:\n",
    "    if 'Vendor_Name' in df.columns:\n",
    "        top_vendors = df[df['Is_Fraud_bool']==1]['Vendor_Name'].value_counts().head(10)\n",
    "        display(top_vendors)\n",
    "        plt.figure(figsize=(10,4))\n",
    "        sns.barplot(x=top_vendors.values, y=top_vendors.index)\n",
    "        plt.title('Top 10 Vendors by Fraud Count')\n",
    "        plt.xlabel('Fraud Count')\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print('Vendor plot skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requested vs Legitimate Amount comparison\n",
    "try:\n",
    "    if {'Requested_Amount_PKR','Legitimate_Estimate_PKR'}.issubset(df.columns):\n",
    "        df['Amount_Gap'] = df['Requested_Amount_PKR'] - df['Legitimate_Estimate_PKR']\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.boxplot(x='Is_Fraud_bool', y='Amount_Gap', data=df)\n",
    "        plt.xticks([0,1], ['Non-Fraud (0)', 'Fraud (1)'])\n",
    "        plt.title('Amount Gap by Fraud Label')\n",
    "        plt.ylabel('Requested - Legitimate (PKR)')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Amount columns not found in dataset.')\n",
    "except Exception as e:\n",
    "    print('Amount gap plot failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numeric features\n",
    "try:\n",
    "    num_df = df.select_dtypes(include=[np.number])\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(num_df.corr(), annot=False, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap (numeric features)')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Heatmap failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a9d2b3",
   "metadata": {},
   "source": [
    "## 4. PyCaret Model Building\n",
    "\n",
    "This section uses PyCaret for automated preprocessing and model selection. The `setup()` call will perform encoding, imputation, transformation, and train/test splitting automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyCaret classification\n",
    "try:\n",
    "    from pycaret.classification import *\n",
    "except Exception as e:\n",
    "    print('PyCaret not installed. To install: !pip install pycaret')\n",
    "\n",
    "# Setup\n",
    "try:\n",
    "    # Use the boolean target column created earlier\n",
    "    s = setup(data=df, target='Is_Fraud_bool', session_id=42, silent=True, \\\n",
    "n_jobs=-1, normalize=True, transformation=True, combine_rare_levels=True, \\\n",
    "remove_multicollinearity=True, ignore_low_variance=True)\n",
    "    \n",
    "    print('PyCaret setup completed. Use compare_models() to find best model.')\n",
    "except Exception as e:\n",
    "    print('PyCaret setup could not run (likely because PyCaret is not installed or dataset not loaded).', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models (automated) - UNCOMMENT to run\n",
    "# best = compare_models(n_select=1)\n",
    "# print(best)\n",
    "\n",
    "print('Run compare_models() when PyCaret is available in your environment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5296f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create, tune and finalize a model (uncomment to run when ready)\n",
    "# model = create_model('rf')\n",
    "# tuned = tune_model(model)\n",
    "# finalize_model(tuned)\n",
    "# save_model(tuned, 'fraud_rf_pycaret')\n",
    "\n",
    "print('Example model commands provided. Uncomment to run in your environment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3bb5b7",
   "metadata": {},
   "source": [
    "## 5. Insights & Next Steps\n",
    "\n",
    "**Key Actions After Running This Notebook:**\n",
    "\n",
    "- Review EDA outputs (fraud concentration by NGO, vendor, bank, and geography).\n",
    "- Run PyCaret `compare_models()` to find the best model automatically.\n",
    "- Evaluate the selected model using `evaluate_model()` and `predict_model()`.\n",
    "- Save the final model with `save_model()` for deployment in production or an API.\n",
    "\n",
    "**Potential Improvements:**\n",
    "\n",
    "- Generate synthetic examples (SMOTE) if the dataset is imbalanced.\n",
    "- Create time-series features (lag counts, rolling fraud-rate) from the `Date` column.\n",
    "- Build an inference pipeline (Flask/FastAPI) for live fraud scoring.\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook created for Tehreem â€” professional, English documentation suitable for GitHub.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
